name: ğŸ§ª Automated Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "18"
  POSTGRES_VERSION: "15"

jobs:
  # ========================================
  # Backend Unit & Integration Tests
  # ========================================
  backend-tests:
    name: ğŸ Backend Tests & Coverage
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: garagereg
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: garagereg_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: ğŸ“¦ Install dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-cov pytest-asyncio pytest-mock pytest-xdist

    - name: ğŸ”§ Configure test environment
      working-directory: ./backend
      run: |
        echo "DATABASE_URL=postgresql://garagereg:test_password@localhost:5432/garagereg_test" >> .env.test
        echo "REDIS_URL=redis://localhost:6379" >> .env.test
        echo "TESTING=true" >> .env.test
        echo "SECRET_KEY=test-secret-key-for-ci-only" >> .env.test

    - name: ğŸ” Run linting
      working-directory: ./backend
      run: |
        # Install linting tools
        pip install flake8 black isort mypy
        
        # Run code formatters and linters
        black --check --diff app/ tests/
        isort --check-only --diff app/ tests/
        flake8 app/ tests/ --max-line-length=88 --extend-ignore=E203,W503
        mypy app/ --ignore-missing-imports

    - name: ğŸ§ª Run unit tests
      working-directory: ./backend
      run: |
        pytest tests/unit/ \
          -v \
          --cov=app \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --cov-fail-under=90 \
          --junit-xml=test-results/unit-results.xml \
          --maxfail=5

    - name: ğŸ”— Run integration tests
      working-directory: ./backend
      run: |
        pytest tests/integration/ \
          -v \
          --cov=app \
          --cov-append \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --junit-xml=test-results/integration-results.xml \
          --maxfail=5

    - name: ğŸŒ Run API tests
      working-directory: ./backend
      run: |
        pytest tests/api/ \
          -v \
          --cov=app \
          --cov-append \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --junit-xml=test-results/api-results.xml \
          --maxfail=5

    - name: ğŸ’¨ Run smoke tests
      working-directory: ./backend
      run: |
        pytest -m smoke \
          --tb=short \
          --maxfail=1 \
          --junit-xml=test-results/smoke-results.xml

    - name: ğŸ“Š Generate coverage report
      working-directory: ./backend
      run: |
        # Generate final coverage report
        coverage combine
        coverage report --show-missing --fail-under=90
        coverage html --title="GarageReg Backend Coverage Report"
        coverage xml

    - name: ğŸ“ˆ Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml
        name: backend-coverage
        fail_ci_if_error: true

    - name: ğŸ“¤ Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: backend-test-results
        path: |
          backend/test-results/
          backend/htmlcov/
          backend/coverage.xml

    - name: ğŸ“ Publish test results
      uses: dorny/test-reporter@v1
      if: always()
      with:
        name: Backend Tests
        path: 'backend/test-results/*.xml'
        reporter: java-junit

  # ========================================
  # Frontend E2E Tests with Playwright
  # ========================================
  frontend-e2e:
    name: ğŸ­ Frontend E2E Tests
    runs-on: ubuntu-latest
    needs: backend-tests
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸŸ¢ Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: web-admin-new/package-lock.json

    - name: ğŸ“¦ Install dependencies
      working-directory: ./web-admin-new
      run: |
        npm ci
        npx playwright install --with-deps

    - name: ğŸ Set up Python for backend
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸš€ Start backend server
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
        # Set up test database
        echo "DATABASE_URL=sqlite:///./test_e2e.db" > .env
        echo "SECRET_KEY=test-secret-for-e2e" >> .env
        echo "TESTING=true" >> .env
        
        # Start backend in background
        python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 &
        sleep 10
      
    - name: ğŸŒ Start frontend server
      working-directory: ./web-admin-new
      run: |
        # Set backend URL
        echo "VITE_API_URL=http://localhost:8000" > .env.local
        
        # Build and start frontend
        npm run build
        npm run preview --port 3000 &
        sleep 10

    - name: ğŸ§ª Run Playwright tests
      working-directory: ./web-admin-new
      run: |
        npx playwright test \
          --reporter=html,junit,json \
          --output-dir=test-results

    - name: ğŸ“¤ Upload Playwright results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: playwright-results
        path: |
          web-admin-new/test-results/
          web-admin-new/playwright-report/

    - name: ğŸ“ Publish E2E test results
      uses: dorny/test-reporter@v1
      if: always()
      with:
        name: E2E Tests
        path: 'web-admin-new/test-results/junit.xml'
        reporter: java-junit

  # ========================================
  # Security Scanning
  # ========================================
  security-scan:
    name: ğŸ” Security Scanning
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ” Run safety check (Python dependencies)
      working-directory: ./backend
      run: |
        pip install safety
        safety check --json --output security-report.json || true

    - name: ğŸ” Run bandit security scan
      working-directory: ./backend
      run: |
        pip install bandit
        bandit -r app/ -f json -o bandit-report.json || true

    - name: ğŸ” Run semgrep scan
      uses: returntocorp/semgrep-action@v1
      with:
        config: auto
        generateSarif: "1"

    - name: ğŸ“¤ Upload security scan results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-scan-results
        path: |
          backend/security-report.json
          backend/bandit-report.json

  # ========================================
  # Performance Testing
  # ========================================
  performance-test:
    name: ğŸ“ˆ Performance Testing
    runs-on: ubuntu-latest
    needs: backend-tests
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4

    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ“¦ Install backend dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install locust

    - name: ğŸš€ Start backend server
      working-directory: ./backend
      run: |
        echo "DATABASE_URL=sqlite:///./test_perf.db" > .env
        echo "SECRET_KEY=test-secret-for-perf" >> .env
        
        # Start server in background
        python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 &
        sleep 10

    - name: ğŸ“Š Run performance tests
      working-directory: ./backend
      run: |
        # Create basic load test
        cat > locustfile.py << 'EOF'
        from locust import HttpUser, task, between
        
        class GarageRegUser(HttpUser):
            wait_time = between(1, 3)
            
            def on_start(self):
                # Login to get auth token
                response = self.client.post("/api/v1/auth/login", data={
                    "username": "testuser", 
                    "password": "testpass"
                })
                if response.status_code == 200:
                    self.token = response.json().get("access_token")
                    self.headers = {"Authorization": f"Bearer {self.token}"}
                else:
                    self.headers = {}
            
            @task(3)
            def get_dashboard(self):
                self.client.get("/api/v1/dashboard", headers=self.headers)
            
            @task(2)  
            def get_organizations(self):
                self.client.get("/api/v1/organizations", headers=self.headers)
            
            @task(1)
            def get_users(self):
                self.client.get("/api/v1/users", headers=self.headers)
        EOF
        
        # Run load test
        locust -f locustfile.py --host=http://localhost:8000 \
               --users=10 --spawn-rate=2 --run-time=60s --html=perf-report.html

    - name: ğŸ“¤ Upload performance results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-results
        path: backend/perf-report.html

  # ========================================
  # Test Summary & Coverage Gates
  # ========================================
  test-summary:
    name: ğŸ“‹ Test Summary & Gates
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-e2e, security-scan]
    if: always()
    
    steps:
    - name: ğŸ“¥ Download all artifacts
      uses: actions/download-artifact@v4
    
    - name: ğŸ“Š Generate test summary
      run: |
        echo "# ğŸ§ª Test Suite Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Backend coverage
        if [ -f backend-test-results/coverage.xml ]; then
          COVERAGE=$(python3 -c "
          import xml.etree.ElementTree as ET
          tree = ET.parse('backend-test-results/coverage.xml')
          root = tree.getroot()
          coverage = root.attrib.get('line-rate', '0')
          print(f'{float(coverage)*100:.1f}%')
          ")
          echo "## ğŸ“Š Backend Coverage: $COVERAGE" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## âœ… Test Status" >> $GITHUB_STEP_SUMMARY
        echo "- Backend Unit Tests: ${{ needs.backend-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Frontend E2E Tests: ${{ needs.frontend-e2e.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Security Scan: ${{ needs.security-scan.result }}" >> $GITHUB_STEP_SUMMARY

    - name: ğŸš¦ Check coverage gates
      run: |
        # Fail if critical tests failed
        if [ "${{ needs.backend-tests.result }}" != "success" ]; then
          echo "âŒ Backend tests failed - blocking merge"
          exit 1
        fi
        
        if [ "${{ needs.frontend-e2e.result }}" != "success" ]; then
          echo "âŒ E2E tests failed - blocking merge"  
          exit 1
        fi
        
        echo "âœ… All test gates passed!"

    - name: ğŸ’¬ Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const { owner, repo, number } = context.issue;
          
          const comment = `
          ## ğŸ§ª Automated Test Results
          
          | Test Suite | Status | 
          |------------|--------|
          | Backend Unit & Integration | ${{ needs.backend-tests.result == 'success' && 'âœ…' || 'âŒ' }} ${{ needs.backend-tests.result }} |
          | Frontend E2E (Playwright) | ${{ needs.frontend-e2e.result == 'success' && 'âœ…' || 'âŒ' }} ${{ needs.frontend-e2e.result }} |
          | Security Scan | ${{ needs.security-scan.result == 'success' && 'âœ…' || 'âŒ' }} ${{ needs.security-scan.result }} |
          
          ### ğŸ“Š Coverage Report
          - Backend coverage reports available in artifacts
          - E2E test reports available in artifacts
          
          **Status**: ${{ needs.backend-tests.result == 'success' && needs.frontend-e2e.result == 'success' && 'ğŸŸ¢ All tests passing' || 'ğŸ”´ Some tests failed' }}
          `;
          
          github.rest.issues.createComment({
            owner,
            repo,  
            issue_number: number,
            body: comment
          });